{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow101-1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPJNIFmxCyN0rsxI+fJ5Euh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datasigntist/tensorflowCodes/blob/master/tensorflow101_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGCOgXs-eKt_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "94bb2518-616c-4764-9157-37b8e0a8b3d4"
      },
      "source": [
        "import functools \n",
        "import numpy as np \n",
        "import tensorflow as tf \n",
        "import pandas as pd\n",
        "\n",
        "LABEL_COLUMN = \"Survived\"\n",
        "\n",
        "TRAIN_DATA_URL=  \"https://raw.githubusercontent.com/datasigntist/datasetsForTraining/master/train.csv\" \n",
        "\n",
        "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL) \n",
        "\n",
        "def get_dataset(file_path, **kwargs):\n",
        "  dataset = tf.data.experimental.make_csv_dataset(\n",
        "      file_path,\n",
        "      batch_size=5, # Artificially small to make examples easier to show.\n",
        "      label_name=LABEL_COLUMN,\n",
        "      na_value=\"?\",\n",
        "      num_epochs=1,\n",
        "      ignore_errors=True, \n",
        "      **kwargs)\n",
        "  return dataset\n",
        "\n",
        "def show_batch(dataset):\n",
        "  for batch, label in dataset.take(1):\n",
        "    for key, value in batch.items():\n",
        "      print(\"{:20s}: {}\".format(key,value.numpy()))\n",
        "\n",
        "titanicDataSet = get_dataset(train_file_path)\n",
        "\n",
        "class extractFeaturesFromName(object):\n",
        "  #def __init__(self):\n",
        "  #  print(\"Initiated\")\n",
        "\n",
        "  def __call__(self, features, labels):\n",
        "    namesOfPassengers = features['Name']\n",
        "    lastName_feature = tf.map_fn(lambda feat: tf.strings.strip(tf.strings.split(feat,\",\")[0]) ,namesOfPassengers)\n",
        "    firstName_feature = tf.map_fn(lambda feat: tf.strings.strip(tf.strings.split(tf.strings.strip(tf.strings.split(feat,\",\")[1]),\".\")[1]) ,namesOfPassengers)\n",
        "    title_feature  = tf.map_fn(lambda feat: tf.strings.strip(tf.strings.split(tf.strings.strip(tf.strings.split(feat,\",\")[1]),\".\")[0]) ,namesOfPassengers)\n",
        "    features['last_name'] = lastName_feature\n",
        "    features['first_name'] = firstName_feature\n",
        "    features['title_feature'] = title_feature\n",
        "    return features, labels\n",
        "\n",
        "class replaceMissingValuesInAge(object):\n",
        "  def __init__(self, meanAge):\n",
        "    self.meanAge = meanAge\n",
        "\n",
        "  def __call__(self, features, labels):\n",
        "    ageOfPassengers = features['Age']\n",
        "    tf.print(ageOfPassengers)\n",
        "    ageOfPassengers = tf.map_fn(lambda age: (age if age>0 else self.meanAge) ,ageOfPassengers)\n",
        "    features['Age'] = ageOfPassengers\n",
        "    return features, labels\n",
        "\n",
        "desc = pd.read_csv(train_file_path)[\"Age\"].describe()\n",
        "MEAN = np.float32(np.array(desc.T['mean']))\n",
        "\n",
        "newtitanicDataSet = titanicDataSet.map(extractFeaturesFromName())\n",
        "newtitanicDataSet = titanicDataSet.map(replaceMissingValuesInAge(MEAN))\n",
        "\n",
        "show_batch(newtitanicDataSet)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 41 0 0 0]\n",
            "PassengerId         : [498 762 869 668  33]\n",
            "Pclass              : [3 3 3 3 3]\n",
            "Name                : [b'Shellard, Mr. Frederick William' b'Nirva, Mr. Iisakki Antino Aijo'\n",
            " b'van Melkebeke, Mr. Philemon' b'Rommetvedt, Mr. Knud Paust'\n",
            " b'Glynn, Miss. Mary Agatha']\n",
            "Sex                 : [b'male' b'male' b'male' b'male' b'female']\n",
            "Age                 : [29.699118 41.       29.699118 29.699118 29.699118]\n",
            "SibSp               : [0 0 0 0 0]\n",
            "Parch               : [0 0 0 0 0]\n",
            "Ticket              : [b'C.A. 6212' b'SOTON/O2 3101272' b'345777' b'312993' b'335677']\n",
            "Fare                : [15.1    7.125  9.5    7.775  7.75 ]\n",
            "Cabin               : [b'' b'' b'' b'' b'']\n",
            "Embarked            : [b'S' b'S' b'S' b'S' b'Q']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dahyhCqekTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}